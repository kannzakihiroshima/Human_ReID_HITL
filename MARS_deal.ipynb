{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3af18-1bd0-40f5-8a84-1ef78788f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# ========== A) MarsTrainLoader & MarsLoader ==========\n",
    "\n",
    "class MarsTrainLoader:\n",
    "    def __init__(self, root, home_dir='bbox_train', min_seq_len=0):\n",
    "        self.root = root\n",
    "        self.home_dir = home_dir\n",
    "        self.min_seq_len = min_seq_len\n",
    "        self.train_dir = os.path.join(self.root, self.home_dir)\n",
    "        self._check_before_run()\n",
    "\n",
    "    def _check_before_run(self):\n",
    "        if not os.path.exists(self.train_dir):\n",
    "            raise RuntimeError(f\"Train directory '{self.train_dir}' does not exist.\")\n",
    "\n",
    "    def load_data(self):\n",
    "        tracklet_dict = {}\n",
    "        for root_dir, _, files in os.walk(self.train_dir):\n",
    "            for fname in files:\n",
    "                if fname.lower().endswith('.jpg'):\n",
    "                    full_path = os.path.join(root_dir, fname)\n",
    "                    pid, camid, track_id, frame_idx = self._parse_filename(fname)\n",
    "                    key = (pid, camid, track_id)\n",
    "                    if key not in tracklet_dict:\n",
    "                        tracklet_dict[key] = []\n",
    "                    tracklet_dict[key].append((frame_idx, full_path))\n",
    "\n",
    "        tracklets = []\n",
    "        tracklet_count = 1\n",
    "        for (pid, camid, tid), frames in tracklet_dict.items():\n",
    "            frames.sort(key=lambda x: x[0])\n",
    "            img_paths = [x[1] for x in frames]\n",
    "            if len(img_paths) >= self.min_seq_len:\n",
    "                tracklets.append((img_paths, pid, camid, tracklet_count))\n",
    "                tracklet_count += 1\n",
    "        return tracklets\n",
    "\n",
    "    def _parse_filename(self, filename):\n",
    "        \"\"\"\n",
    "        例: '0000C1T0001F009.jpg'\n",
    "          pid=0000, camid=1, trackid=0001, frame_idx=009\n",
    "        \"\"\"\n",
    "        name, _ = os.path.splitext(filename)\n",
    "        pid_str     = name[0:4]\n",
    "        camid_str   = name[5]\n",
    "        trackid_str = name[7:11]\n",
    "        frameid_str = name[12:]\n",
    "        return int(pid_str), int(camid_str), int(trackid_str), int(frameid_str)\n",
    "\n",
    "\n",
    "class MarsLoader:\n",
    "    def __init__(self, root, min_seq_len=0):\n",
    "        self.root = root\n",
    "        self.min_seq_len = min_seq_len\n",
    "        self.test_name_path = os.path.join(root, 'test_name.txt')\n",
    "        self.track_test_info_path = os.path.join(root, 'tracks_test_info.mat')\n",
    "        self.query_IDX_path = os.path.join(root, 'query_IDX.mat')\n",
    "        self._check_before_run()\n",
    "\n",
    "        self.test_names = self._get_names(self.test_name_path)\n",
    "        self.track_test = loadmat(self.track_test_info_path)['track_test_info']\n",
    "        self.query_IDX  = loadmat(self.query_IDX_path)['query_IDX'].squeeze() - 1\n",
    "\n",
    "        self.track_query = self.track_test[self.query_IDX, :]\n",
    "        all_idx = set(range(self.track_test.shape[0]))\n",
    "        query_idx_set = set(self.query_IDX.tolist())\n",
    "        self.gallery_IDX = list(all_idx - query_idx_set)\n",
    "        self.track_gallery = self.track_test[self.gallery_IDX, :]\n",
    "\n",
    "    def _check_before_run(self):\n",
    "        required_files = [\n",
    "            self.test_name_path,\n",
    "            self.track_test_info_path,\n",
    "            self.query_IDX_path\n",
    "        ]\n",
    "        for f in required_files:\n",
    "            if not os.path.exists(f):\n",
    "                raise RuntimeError(f\"'{f}' does not exist.\")\n",
    "\n",
    "    def _get_names(self, fpath):\n",
    "        with open(fpath, 'r') as f:\n",
    "            names = [line.strip() for line in f.readlines()]\n",
    "        return names\n",
    "\n",
    "    def load_data(self, home_dir='bbox_test'):\n",
    "        query_data   = self._process_data(self.track_query, home_dir)\n",
    "        gallery_data = self._process_data(self.track_gallery, home_dir)\n",
    "        return query_data, gallery_data\n",
    "\n",
    "    def _process_data(self, track_info, home_dir):\n",
    "        tracklets = []\n",
    "        for row in track_info:\n",
    "            start_idx, end_idx, pid, camid = row\n",
    "            if pid == -1 or pid == 0:\n",
    "                continue\n",
    "            camid = camid - 1\n",
    "            img_names = self.test_names[start_idx - 1 : end_idx]\n",
    "            img_paths = [\n",
    "                os.path.join(self.root, home_dir, name[:4], name)\n",
    "                for name in img_names\n",
    "            ]\n",
    "            if len(img_paths) >= self.min_seq_len:\n",
    "                tracklets.append((img_paths, int(pid), int(camid)))\n",
    "        return tracklets\n",
    "\n",
    "\n",
    "# ========== B) カスタムDataset ==========\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None, is_aug=0, aug_id=0):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform   = transform\n",
    "        self.is_aug      = is_aug\n",
    "        self.aug_id      = aug_id\n",
    "        self.skipped_files = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, path\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: {e}\")\n",
    "            self.skipped_files.append(path)\n",
    "            return None\n",
    "\n",
    "\n",
    "def skip_none_collate(batch):\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None\n",
    "    return default_collate(batch)\n",
    "\n",
    "\n",
    "# ========== C) バッチ単位でpklへ保存 ==========\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_embeddings_and_save_batchwise_pkl(\n",
    "    dataloader, model, device,\n",
    "    pkl_path,\n",
    "    pids=None,\n",
    "    camids=None,\n",
    "    tids=None,\n",
    "    is_aug=0,\n",
    "    aug_id=0,\n",
    "    append_mode=False\n",
    "):\n",
    "    \"\"\"\n",
    "    バッチ毎に埋め込みを抽出し、pickleファイルに書き出す。\n",
    "    保存する内容は、各サンプルごとに以下の辞書情報:\n",
    "      - file_name: 画像パス\n",
    "      - embedding: 埋め込みベクトル (list形式)\n",
    "      - pid, camid, tracklet_id, is_aug, aug_id\n",
    "    append_mode=True の場合、既存のpklファイルがあれば内容に追加します。\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    total_samples = len(dataloader.dataset)\n",
    "\n",
    "    loader_iter = iter(dataloader)\n",
    "    first_batch = next(loader_iter, None)\n",
    "    if first_batch is None:\n",
    "        print(\"No data in dataloader.\")\n",
    "        return\n",
    "    images, file_paths = first_batch\n",
    "    images = images.to(device)\n",
    "    feats = model(images).cpu().numpy()  # shape=(B, feat_dim)\n",
    "\n",
    "    global_idx = 0\n",
    "    B = feats.shape[0]\n",
    "    for i in range(B):\n",
    "        row = {\n",
    "            \"file_name\": file_paths[i],\n",
    "            \"embedding\": feats[i].tolist(),\n",
    "            \"pid\": pids[global_idx],\n",
    "            \"camid\": camids[global_idx],\n",
    "            \"tracklet_id\": tids[global_idx],\n",
    "            \"is_aug\": is_aug,\n",
    "            \"aug_id\": aug_id\n",
    "        }\n",
    "        all_data.append(row)\n",
    "        global_idx += 1\n",
    "\n",
    "    batch_idx = 1\n",
    "    for batch in loader_iter:\n",
    "        if batch is None:\n",
    "            continue\n",
    "        images, file_paths = batch\n",
    "        images = images.to(device)\n",
    "        feats = model(images).cpu().numpy()\n",
    "        B = feats.shape[0]\n",
    "        for i in range(B):\n",
    "            row = {\n",
    "                \"file_name\": file_paths[i],\n",
    "                \"embedding\": feats[i].tolist(),\n",
    "                \"pid\": pids[global_idx],\n",
    "                \"camid\": camids[global_idx],\n",
    "                \"tracklet_id\": tids[global_idx],\n",
    "                \"is_aug\": is_aug,\n",
    "                \"aug_id\": aug_id\n",
    "            }\n",
    "            all_data.append(row)\n",
    "            global_idx += 1\n",
    "\n",
    "        batch_idx += 1\n",
    "        print(f\"Processed batch={batch_idx}, total={global_idx}/{total_samples}\")\n",
    "\n",
    "    # 既存ファイルがあれば内容を追加\n",
    "    if append_mode and os.path.exists(pkl_path):\n",
    "        with open(pkl_path, \"rb\") as f_in:\n",
    "            existing_data = pickle.load(f_in)\n",
    "        all_data = existing_data + all_data\n",
    "\n",
    "    with open(pkl_path, \"wb\") as f_out:\n",
    "        pickle.dump(all_data, f_out)\n",
    "    print(f\"Saved PKL: {pkl_path}, total written={total_samples}\")\n",
    "\n",
    "\n",
    "# ========== D) メイン: ===================\n",
    "if __name__ == \"__main__\":\n",
    "    root_path = \"C:/Users/sugie/PycharmProjects/pythonProject10/MARS\"\n",
    "\n",
    "    #--------------------------------\n",
    "    # (1) Trainデータ読み込み & フラット化\n",
    "    #--------------------------------\n",
    "    train_loader_obj = MarsTrainLoader(root=root_path, home_dir='bbox_train/bbox_train')\n",
    "    train_data = train_loader_obj.load_data()\n",
    "    print(f\"[Train] Loaded tracklets: {len(train_data)}\")\n",
    "\n",
    "    # pid <= 300 のみに絞る\n",
    "    filtered_train_data = []\n",
    "    for (img_paths, pid, camid, tid) in train_data:\n",
    "        if pid <= 3000:\n",
    "            filtered_train_data.append((img_paths, pid, camid, tid))\n",
    "    train_data = filtered_train_data\n",
    "    print(f\"[Train] tracklets after filtering: {len(train_data)}\")\n",
    "\n",
    "    # フラット化\n",
    "    final_train_samples = []\n",
    "    for (img_paths, pid, camid, tid) in train_data:\n",
    "        for p in img_paths:\n",
    "            final_train_samples.append((p, pid, camid, tid))\n",
    "    print(f\"Final train images: {len(final_train_samples)}\")\n",
    "\n",
    "    train_image_paths = [x[0] for x in final_train_samples]\n",
    "    train_pids        = [x[1] for x in final_train_samples]\n",
    "    train_camids      = [x[2] for x in final_train_samples]\n",
    "    train_tids        = [x[3] for x in final_train_samples]\n",
    "\n",
    "    #--------------------------------\n",
    "    # (2) Query & Gallery\n",
    "    #--------------------------------\n",
    "    test_loader_obj = MarsLoader(root=root_path)\n",
    "    query_data, gallery_data = test_loader_obj.load_data(home_dir='bbox_test/bbox_test')\n",
    "\n",
    "    # Query\n",
    "    filtered_query_data = []\n",
    "    for (img_paths, pid, camid) in query_data:\n",
    "        if pid <= 3000:\n",
    "            filtered_query_data.append((img_paths, pid, camid))\n",
    "    query_data = filtered_query_data\n",
    "\n",
    "    final_query_samples = []\n",
    "    query_tid = 1\n",
    "    for (img_paths, pid, camid) in query_data:\n",
    "        for p in img_paths:\n",
    "            final_query_samples.append((p, pid, camid, query_tid))\n",
    "        query_tid += 1\n",
    "\n",
    "    query_image_paths = [x[0] for x in final_query_samples]\n",
    "    query_pids        = [x[1] for x in final_query_samples]\n",
    "    query_camids      = [x[2] for x in final_query_samples]\n",
    "    query_tids        = [x[3] for x in final_query_samples]\n",
    "\n",
    "    # Gallery\n",
    "    filtered_gallery_data = []\n",
    "    for (img_paths, pid, camid) in gallery_data:\n",
    "        if pid <= 3000:\n",
    "            filtered_gallery_data.append((img_paths, pid, camid))\n",
    "    gallery_data = filtered_gallery_data\n",
    "\n",
    "    final_gallery_samples = []\n",
    "    gallery_tid = 1\n",
    "    for (img_paths, pid, camid) in gallery_data:\n",
    "        for p in img_paths:\n",
    "            final_gallery_samples.append((p, pid, camid, gallery_tid))\n",
    "        gallery_tid += 1\n",
    "\n",
    "    gallery_image_paths = [x[0] for x in final_gallery_samples]\n",
    "    gallery_pids        = [x[1] for x in final_gallery_samples]\n",
    "    gallery_camids      = [x[2] for x in final_gallery_samples]\n",
    "    gallery_tids        = [x[3] for x in final_gallery_samples]\n",
    "\n",
    "    #--------------------------------\n",
    "    # (3) モデルの準備 (ResNet50)\n",
    "    #--------------------------------\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = models.resnet50(pretrained=False)\n",
    "    model.fc = nn.Identity()\n",
    "    checkpoint = torch.load(\"C:/Users/sugie/PycharmProjects/pythonProject10/MARS/resnet50_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter.pth\", map_location=device)\n",
    "    state_dict = checkpoint.get(\"state_dict\", checkpoint)\n",
    "    state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.to(device).eval()\n",
    "\n",
    "    #--------------------------------\n",
    "    # (4) 変換定義\n",
    "    #--------------------------------\n",
    "    transform_no_aug = transforms.Compose([\n",
    "        transforms.Resize((256, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    def get_aug_transform():\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomResizedCrop(\n",
    "                size=(256, 128),\n",
    "                scale=(0.8, 1.0),\n",
    "                ratio=(0.75, 1.3333)\n",
    "            ),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1\n",
    "            ),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225]),\n",
    "            transforms.RandomErasing(p=0.5, scale=(0.02, 0.25))\n",
    "        ])\n",
    "\n",
    "    #--------------------------------\n",
    "    # (5) Dataset & Loader: Query は従来通り\n",
    "    #--------------------------------\n",
    "    query_dataset_noaug = ImageDataset(query_image_paths, transform_no_aug, is_aug=0, aug_id=0)\n",
    "    query_loader_noaug  = DataLoader(query_dataset_noaug, batch_size=64, shuffle=False, collate_fn=skip_none_collate)\n",
    "\n",
    "    #--------------------------------\n",
    "    # (★A) Train: PIDごとに50刻みで分割してpkl出力\n",
    "    #--------------------------------\n",
    "    # Train全体のサンプル（final_train_samples）は (img_path, pid, camid, tracklet_id)\n",
    "    # PIDを 0～49, 50～99, ... と分割します。\n",
    "    unique_train_pids = sorted(list(set(train_pids)))\n",
    "    chunk_size = 50\n",
    "    chunk_starts = list(range(0, 3001, chunk_size))\n",
    "    # Train用Augmentation回数（必要なら変更）\n",
    "    N_AUG_TRAIN = 0\n",
    "\n",
    "    for start_pid in chunk_starts:\n",
    "        end_pid = start_pid + chunk_size\n",
    "        train_pkl_path_chunk = f\"train_embeddings_chunk_ReSNet_all_{start_pid}_{end_pid-1}.pkl\"\n",
    "        # PIDが [start_pid, end_pid-1] のサンプルを抽出\n",
    "        chunk_indices = [i for i, pid in enumerate(train_pids) if start_pid <= pid < end_pid]\n",
    "        if len(chunk_indices) == 0:\n",
    "            continue\n",
    "        chunk_image_paths = [train_image_paths[i] for i in chunk_indices]\n",
    "        chunk_pids        = [train_pids[i]        for i in chunk_indices]\n",
    "        chunk_camids      = [train_camids[i]      for i in chunk_indices]\n",
    "        chunk_tids        = [train_tids[i]        for i in chunk_indices]\n",
    "\n",
    "        # ---- (A) オリジナル ----\n",
    "        train_dataset_noaug_chunk = ImageDataset(\n",
    "            chunk_image_paths,\n",
    "            transform_no_aug,\n",
    "            is_aug=0, aug_id=0\n",
    "        )\n",
    "        train_loader_noaug_chunk  = DataLoader(\n",
    "            train_dataset_noaug_chunk,\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            collate_fn=skip_none_collate\n",
    "        )\n",
    "\n",
    "        extract_embeddings_and_save_batchwise_pkl(\n",
    "            dataloader=train_loader_noaug_chunk,\n",
    "            model=model,\n",
    "            device=device,\n",
    "            pkl_path=train_pkl_path_chunk,\n",
    "            pids=chunk_pids,\n",
    "            camids=chunk_camids,\n",
    "            tids=chunk_tids,\n",
    "            is_aug=0,\n",
    "            aug_id=0,\n",
    "            append_mode=False\n",
    "        )\n",
    "\n",
    "        # ---- (B) オーグメンテーション（N_AUG_TRAIN回）----\n",
    "        for aug_i in range(1, N_AUG_TRAIN+1):\n",
    "            transform_aug = get_aug_transform()\n",
    "            train_dataset_aug_chunk = ImageDataset(\n",
    "                chunk_image_paths,\n",
    "                transform_aug,\n",
    "                is_aug=1, aug_id=aug_i\n",
    "            )\n",
    "            train_loader_aug_chunk  = DataLoader(\n",
    "                train_dataset_aug_chunk,\n",
    "                batch_size=64,\n",
    "                shuffle=False,\n",
    "                collate_fn=skip_none_collate\n",
    "            )\n",
    "\n",
    "            extract_embeddings_and_save_batchwise_pkl(\n",
    "                dataloader=train_loader_aug_chunk,\n",
    "                model=model,\n",
    "                device=device,\n",
    "                pkl_path=train_pkl_path_chunk,\n",
    "                pids=chunk_pids,\n",
    "                camids=chunk_camids,\n",
    "                tids=chunk_tids,\n",
    "                is_aug=1,\n",
    "                aug_id=aug_i,\n",
    "                append_mode=True\n",
    "            )\n",
    "        print(f\"Done train chunk [PID {start_pid}..{end_pid-1}]. PKL => {train_pkl_path_chunk}\")\n",
    "\n",
    "    --------------------------------\n",
    "    (★B) Query: PIDごとに50刻みで分割してpkl出力\n",
    "    --------------------------------\n",
    "    unique_query_pids = sorted(list(set(query_pids)))\n",
    "    chunk_size = 50\n",
    "    chunk_starts = list(range(0, 3001, chunk_size))\n",
    "    N_AUG_QUERY = 3\n",
    "\n",
    "    for start_pid in chunk_starts:\n",
    "        end_pid = start_pid + chunk_size\n",
    "        query_pkl_path_chunk = f\"query_embeddings_chunk_ReSNet_all_{start_pid}_{end_pid - 1}.pkl\"\n",
    "\n",
    "        chunk_indices = [i for i, pid in enumerate(query_pids) if start_pid <= pid < end_pid]\n",
    "        if len(chunk_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        chunk_image_paths = [query_image_paths[i] for i in chunk_indices]\n",
    "        chunk_pids = [query_pids[i] for i in chunk_indices]\n",
    "        chunk_camids = [query_camids[i] for i in chunk_indices]\n",
    "        chunk_tids = [query_tids[i] for i in chunk_indices]\n",
    "\n",
    "        # ---- (A) オリジナル ----\n",
    "        query_dataset_noaug_chunk = ImageDataset(\n",
    "            chunk_image_paths,\n",
    "            transform_no_aug,\n",
    "            is_aug=0, aug_id=0\n",
    "        )\n",
    "        query_loader_noaug_chunk = DataLoader(\n",
    "            query_dataset_noaug_chunk,\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            collate_fn=skip_none_collate\n",
    "        )\n",
    "\n",
    "        extract_embeddings_and_save_batchwise_pkl(\n",
    "            dataloader=query_loader_noaug_chunk,\n",
    "            model=model,\n",
    "            device=device,\n",
    "            pkl_path=query_pkl_path_chunk,\n",
    "            pids=chunk_pids,\n",
    "            camids=chunk_camids,\n",
    "            tids=chunk_tids,\n",
    "            is_aug=0,\n",
    "            aug_id=0,\n",
    "            append_mode=False\n",
    "        )\n",
    "\n",
    "        # ---- (B) オーグメンテーション ----\n",
    "        for aug_i in range(1, N_AUG_QUERY + 1):\n",
    "            transform_aug = get_aug_transform()\n",
    "            query_dataset_aug_chunk = ImageDataset(\n",
    "                chunk_image_paths,\n",
    "                transform_aug,\n",
    "                is_aug=1, aug_id=aug_i\n",
    "            )\n",
    "            query_loader_aug_chunk = DataLoader(\n",
    "                query_dataset_aug_chunk,\n",
    "                batch_size=64,\n",
    "                shuffle=False,\n",
    "                collate_fn=skip_none_collate\n",
    "            )\n",
    "\n",
    "            extract_embeddings_and_save_batchwise_pkl(\n",
    "                dataloader=query_loader_aug_chunk,\n",
    "                model=model,\n",
    "                device=device,\n",
    "                pkl_path=query_pkl_path_chunk,\n",
    "                pids=chunk_pids,\n",
    "                camids=chunk_camids,\n",
    "                tids=chunk_tids,\n",
    "                is_aug=1,\n",
    "                aug_id=aug_i,\n",
    "                append_mode=True\n",
    "            )\n",
    "        print(f\"Done query chunk [PID {start_pid}..{end_pid - 1}]. PKL => {query_pkl_path_chunk}\")\n",
    "\n",
    "    #--------------------------------\n",
    "    # (★C) Gallery: PIDごとに50刻みで分割してpkl出力\n",
    "    #--------------------------------\n",
    "    unique_gallery_pids = sorted(list(set(gallery_pids)))\n",
    "    chunk_size = 25\n",
    "    chunk_starts = list(range(0, 3001, chunk_size))\n",
    "    N_AUG_GAL = 3\n",
    "\n",
    "    for start_pid in chunk_starts:\n",
    "        end_pid = start_pid + chunk_size\n",
    "        gallery_pkl_path_chunk = f\"gallery_embeddings_chunk_ReSNet_all_{start_pid}_{end_pid-1}.pkl\"\n",
    "\n",
    "        chunk_indices = [i for i, pid in enumerate(gallery_pids)\n",
    "                         if start_pid <= pid < end_pid]\n",
    "        if len(chunk_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        chunk_image_paths = [gallery_image_paths[i] for i in chunk_indices]\n",
    "        chunk_pids        = [gallery_pids[i]        for i in chunk_indices]\n",
    "        chunk_camids      = [gallery_camids[i]      for i in chunk_indices]\n",
    "        chunk_tids        = [gallery_tids[i]        for i in chunk_indices]\n",
    "\n",
    "        # ---- (A) オリジナル ----\n",
    "        gallery_dataset_noaug_chunk = ImageDataset(\n",
    "            chunk_image_paths,\n",
    "            transform_no_aug,\n",
    "            is_aug=0, aug_id=0\n",
    "        )\n",
    "        gallery_loader_noaug_chunk  = DataLoader(\n",
    "            gallery_dataset_noaug_chunk,\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            collate_fn=skip_none_collate\n",
    "        )\n",
    "\n",
    "        extract_embeddings_and_save_batchwise_pkl(\n",
    "            dataloader=gallery_loader_noaug_chunk,\n",
    "            model=model,\n",
    "            device=device,\n",
    "            pkl_path=gallery_pkl_path_chunk,\n",
    "            pids=chunk_pids,\n",
    "            camids=chunk_camids,\n",
    "            tids=chunk_tids,\n",
    "            is_aug=0,\n",
    "            aug_id=0,\n",
    "            append_mode=False\n",
    "        )\n",
    "\n",
    "        # ---- (B) オーグメンテーション ----\n",
    "        for aug_i in range(1, N_AUG_GAL+1):\n",
    "            transform_aug = get_aug_transform()\n",
    "            gallery_dataset_aug_chunk = ImageDataset(\n",
    "                chunk_image_paths,\n",
    "                transform_aug,\n",
    "                is_aug=1, aug_id=aug_i\n",
    "            )\n",
    "            gallery_loader_aug_chunk  = DataLoader(\n",
    "                gallery_dataset_aug_chunk,\n",
    "                batch_size=64,\n",
    "                shuffle=False,\n",
    "                collate_fn=skip_none_collate\n",
    "            )\n",
    "\n",
    "            extract_embeddings_and_save_batchwise_pkl(\n",
    "                dataloader=gallery_loader_aug_chunk,\n",
    "                model=model,\n",
    "                device=device,\n",
    "                pkl_path=gallery_pkl_path_chunk,\n",
    "                pids=chunk_pids,\n",
    "                camids=chunk_camids,\n",
    "                tids=chunk_tids,\n",
    "                is_aug=1,\n",
    "                aug_id=aug_i,\n",
    "                append_mode=True\n",
    "            )\n",
    "        print(f\"Done gallery chunk [PID {start_pid}..{end_pid-1}]. PKL => {gallery_pkl_path_chunk}\")\n",
    "\n",
    "    print(\"\\nAll done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f41f95-5d3d-46d8-bb6f-1976b55bc18e",
   "metadata": {},
   "source": [
    "# 必要ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6cd7ab0-4a23-4c9f-8388-a790572986b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loadmat\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875c9ff9-b512-4c7b-8b09-c20178f71f16",
   "metadata": {},
   "source": [
    "# データ読込（関数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31eec4e-e2ea-4399-9ef7-418b211ca56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== A) MarsTrainLoader & MarsLoader ==========\n",
    "\n",
    "class MarsTrainLoader:\n",
    "    def __init__(self, root, home_dir='bbox_train', min_seq_len=0):\n",
    "        self.root = root\n",
    "        self.home_dir = home_dir\n",
    "        self.min_seq_len = min_seq_len\n",
    "        self.train_dir = os.path.join(self.root, self.home_dir)\n",
    "        self._check_before_run()\n",
    "\n",
    "    def _check_before_run(self):\n",
    "        if not os.path.exists(self.train_dir):\n",
    "            raise RuntimeError(f\"Train directory '{self.train_dir}' does not exist.\")\n",
    "\n",
    "    def load_data(self):\n",
    "        tracklet_dict = {}\n",
    "        for root_dir, _, files in os.walk(self.train_dir):\n",
    "            for fname in files:\n",
    "                if fname.lower().endswith('.jpg'):\n",
    "                    full_path = os.path.join(root_dir, fname)\n",
    "                    pid, camid, track_id, frame_idx = self._parse_filename(fname)\n",
    "                    key = (pid, camid, track_id)\n",
    "                    if key not in tracklet_dict:\n",
    "                        tracklet_dict[key] = []\n",
    "                    tracklet_dict[key].append((frame_idx, full_path))\n",
    "\n",
    "        tracklets = []\n",
    "        tracklet_count = 1\n",
    "        for (pid, camid, tid), frames in tracklet_dict.items():\n",
    "            frames.sort(key=lambda x: x[0])\n",
    "            img_paths = [x[1] for x in frames]\n",
    "            if len(img_paths) >= self.min_seq_len:\n",
    "                tracklets.append((img_paths, pid, camid, tracklet_count))\n",
    "                tracklet_count += 1\n",
    "        return tracklets\n",
    "\n",
    "    def _parse_filename(self, filename):\n",
    "        \"\"\"\n",
    "        例: '0000C1T0001F009.jpg'\n",
    "          pid=0000, camid=1, trackid=0001, frame_idx=009\n",
    "        \"\"\"\n",
    "        name, _ = os.path.splitext(filename)\n",
    "        pid_str     = name[0:4]\n",
    "        camid_str   = name[5]\n",
    "        trackid_str = name[7:11]\n",
    "        frameid_str = name[12:]\n",
    "        return int(pid_str), int(camid_str), int(trackid_str), int(frameid_str)\n",
    "\n",
    "\n",
    "class MarsLoader:\n",
    "    def __init__(self, root, min_seq_len=0):\n",
    "        self.root = root\n",
    "        self.min_seq_len = min_seq_len\n",
    "        self.test_name_path = os.path.join(root, 'test_name.txt')\n",
    "        self.track_test_info_path = os.path.join(root, 'tracks_test_info.mat')\n",
    "        self.query_IDX_path = os.path.join(root, 'query_IDX.mat')\n",
    "        self._check_before_run()\n",
    "\n",
    "        self.test_names = self._get_names(self.test_name_path)\n",
    "        self.track_test = loadmat(self.track_test_info_path)['track_test_info']\n",
    "        self.query_IDX  = loadmat(self.query_IDX_path)['query_IDX'].squeeze() - 1\n",
    "\n",
    "        self.track_query = self.track_test[self.query_IDX, :]\n",
    "        all_idx = set(range(self.track_test.shape[0]))\n",
    "        query_idx_set = set(self.query_IDX.tolist())\n",
    "        self.gallery_IDX = list(all_idx - query_idx_set)\n",
    "        self.track_gallery = self.track_test[self.gallery_IDX, :]\n",
    "\n",
    "    def _check_before_run(self):\n",
    "        required_files = [\n",
    "            self.test_name_path,\n",
    "            self.track_test_info_path,\n",
    "            self.query_IDX_path\n",
    "        ]\n",
    "        for f in required_files:\n",
    "            if not os.path.exists(f):\n",
    "                raise RuntimeError(f\"'{f}' does not exist.\")\n",
    "\n",
    "    def _get_names(self, fpath):\n",
    "        with open(fpath, 'r') as f:\n",
    "            names = [line.strip() for line in f.readlines()]\n",
    "        return names\n",
    "\n",
    "    def load_data(self, home_dir='bbox_test'):\n",
    "        query_data   = self._process_data(self.track_query, home_dir)\n",
    "        gallery_data = self._process_data(self.track_gallery, home_dir)\n",
    "        return query_data, gallery_data\n",
    "\n",
    "    def _process_data(self, track_info, home_dir):\n",
    "        tracklets = []\n",
    "        for row in track_info:\n",
    "            start_idx, end_idx, pid, camid = row\n",
    "            if pid == -1 or pid == 0:\n",
    "                continue\n",
    "            camid = camid - 1\n",
    "            img_names = self.test_names[start_idx - 1 : end_idx]\n",
    "            img_paths = [\n",
    "                os.path.join(self.root, home_dir, name[:4], name)\n",
    "                for name in img_names\n",
    "            ]\n",
    "            if len(img_paths) >= self.min_seq_len:\n",
    "                tracklets.append((img_paths, int(pid), int(camid)))\n",
    "        return tracklets\n",
    "\n",
    "\n",
    "# ========== B) カスタムDataset ==========\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None, is_aug=0, aug_id=0):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform   = transform\n",
    "        self.is_aug      = is_aug\n",
    "        self.aug_id      = aug_id\n",
    "        self.skipped_files = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, path\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: {e}\")\n",
    "            self.skipped_files.append(path)\n",
    "            return None\n",
    "\n",
    "\n",
    "def skip_none_collate(batch):\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None\n",
    "    return default_collate(batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a94dd0-3882-4ef9-b551-92689ed3ed62",
   "metadata": {},
   "source": [
    "# 特徴量抽出　（関数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbff1618-bdec-4229-9917-ad729a408903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== C) バッチ単位でpklへ保存 ==========\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_embeddings_and_save_batchwise_pkl(\n",
    "    dataloader, model, device,\n",
    "    pkl_path,\n",
    "    pids=None,\n",
    "    camids=None,\n",
    "    tids=None,\n",
    "    is_aug=0,\n",
    "    aug_id=0,\n",
    "    append_mode=False\n",
    "):\n",
    "    \"\"\"\n",
    "    バッチ毎に埋め込みを抽出し、pickleファイルに書き出す。\n",
    "    保存する内容は、各サンプルごとに以下の辞書情報:\n",
    "      - file_name: 画像パス\n",
    "      - embedding: 埋め込みベクトル (list形式)\n",
    "      - pid, camid, tracklet_id, is_aug, aug_id\n",
    "    append_mode=True の場合、既存のpklファイルがあれば内容に追加します。\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    total_samples = len(dataloader.dataset)\n",
    "\n",
    "    loader_iter = iter(dataloader)\n",
    "    first_batch = next(loader_iter, None)\n",
    "    if first_batch is None:\n",
    "        print(\"No data in dataloader.\")\n",
    "        return\n",
    "    images, file_paths = first_batch\n",
    "    images = images.to(device)\n",
    "    feats = model(images).cpu().numpy()  # shape=(B, feat_dim)\n",
    "\n",
    "    global_idx = 0\n",
    "    B = feats.shape[0]\n",
    "    for i in range(B):\n",
    "        row = {\n",
    "            \"file_name\": file_paths[i],\n",
    "            \"embedding\": feats[i].tolist(),\n",
    "            \"pid\": pids[global_idx],\n",
    "            \"camid\": camids[global_idx],\n",
    "            \"tracklet_id\": tids[global_idx],\n",
    "            \"is_aug\": is_aug,\n",
    "            \"aug_id\": aug_id\n",
    "        }\n",
    "        all_data.append(row)\n",
    "        global_idx += 1\n",
    "\n",
    "    batch_idx = 1\n",
    "    for batch in loader_iter:\n",
    "        if batch is None:\n",
    "            continue\n",
    "        images, file_paths = batch\n",
    "        images = images.to(device)\n",
    "        feats = model(images).cpu().numpy()\n",
    "        B = feats.shape[0]\n",
    "        for i in range(B):\n",
    "            row = {\n",
    "                \"file_name\": file_paths[i],\n",
    "                \"embedding\": feats[i].tolist(),\n",
    "                \"pid\": pids[global_idx],\n",
    "                \"camid\": camids[global_idx],\n",
    "                \"tracklet_id\": tids[global_idx],\n",
    "                \"is_aug\": is_aug,\n",
    "                \"aug_id\": aug_id\n",
    "            }\n",
    "            all_data.append(row)\n",
    "            global_idx += 1\n",
    "\n",
    "        batch_idx += 1\n",
    "        print(f\"Processed batch={batch_idx}, total={global_idx}/{total_samples}\")\n",
    "\n",
    "    # 既存ファイルがあれば内容を追加\n",
    "    if append_mode and os.path.exists(pkl_path):\n",
    "        with open(pkl_path, \"rb\") as f_in:\n",
    "            existing_data = pickle.load(f_in)\n",
    "        all_data = existing_data + all_data\n",
    "\n",
    "    with open(pkl_path, \"wb\") as f_out:\n",
    "        pickle.dump(all_data, f_out)\n",
    "    print(f\"Saved PKL: {pkl_path}, total written={total_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b5fd7a-3d67-4c12-bfbb-0fb2a4aa6f4a",
   "metadata": {},
   "source": [
    "# コード実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb61c3c7-05aa-4d05-9f19-b582f71a3879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MarsTrainLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m root_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/sugie/PycharmProjects/pythonProject10/MARS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#--------------------------------\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# (1) Trainデータ読み込み & フラット化\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#--------------------------------\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m train_loader_obj \u001b[38;5;241m=\u001b[39m \u001b[43mMarsTrainLoader\u001b[49m(root\u001b[38;5;241m=\u001b[39mroot_path, home_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbbox_train/bbox_train\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m train_data \u001b[38;5;241m=\u001b[39m train_loader_obj\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Train] Loaded tracklets: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MarsTrainLoader' is not defined"
     ]
    }
   ],
   "source": [
    "# ========== D) メイン: ===================\n",
    "if __name__ == \"__main__\":\n",
    "    root_path = \"C:/Users/sugie/PycharmProjects/pythonProject10/MARS\"\n",
    "\n",
    "    #--------------------------------\n",
    "    # (1) Trainデータ読み込み & フラット化\n",
    "    #--------------------------------\n",
    "    train_loader_obj = MarsTrainLoader(root=root_path, home_dir='bbox_train/bbox_train')\n",
    "    train_data = train_loader_obj.load_data()\n",
    "    print(f\"[Train] Loaded tracklets: {len(train_data)}\")\n",
    "\n",
    "    # pid <= 300 のみに絞る\n",
    "    filtered_train_data = []\n",
    "    for (img_paths, pid, camid, tid) in train_data:\n",
    "        if pid <= 3000:\n",
    "            filtered_train_data.append((img_paths, pid, camid, tid))\n",
    "    train_data = filtered_train_data\n",
    "    print(f\"[Train] tracklets after filtering: {len(train_data)}\")\n",
    "\n",
    "    # フラット化\n",
    "    final_train_samples = []\n",
    "    for (img_paths, pid, camid, tid) in train_data:\n",
    "        for p in img_paths:\n",
    "            final_train_samples.append((p, pid, camid, tid))\n",
    "    print(f\"Final train images: {len(final_train_samples)}\")\n",
    "\n",
    "    train_image_paths = [x[0] for x in final_train_samples]\n",
    "    train_pids        = [x[1] for x in final_train_samples]\n",
    "    train_camids      = [x[2] for x in final_train_samples]\n",
    "    train_tids        = [x[3] for x in final_train_samples]\n",
    "\n",
    "    #--------------------------------\n",
    "    # (2) Query & Gallery\n",
    "    #--------------------------------\n",
    "    test_loader_obj = MarsLoader(root=root_path)\n",
    "    query_data, gallery_data = test_loader_obj.load_data(home_dir='bbox_test/bbox_test')\n",
    "\n",
    "    # Query\n",
    "    filtered_query_data = []\n",
    "    for (img_paths, pid, camid) in query_data:\n",
    "        if pid <= 3000:\n",
    "            filtered_query_data.append((img_paths, pid, camid))\n",
    "    query_data = filtered_query_data\n",
    "\n",
    "    final_query_samples = []\n",
    "    query_tid = 1\n",
    "    for (img_paths, pid, camid) in query_data:\n",
    "        for p in img_paths:\n",
    "            final_query_samples.append((p, pid, camid, query_tid))\n",
    "        query_tid += 1\n",
    "\n",
    "    query_image_paths = [x[0] for x in final_query_samples]\n",
    "    query_pids        = [x[1] for x in final_query_samples]\n",
    "    query_camids      = [x[2] for x in final_query_samples]\n",
    "    query_tids        = [x[3] for x in final_query_samples]\n",
    "\n",
    "    # Gallery\n",
    "    filtered_gallery_data = []\n",
    "    for (img_paths, pid, camid) in gallery_data:\n",
    "        if pid <= 3000:\n",
    "            filtered_gallery_data.append((img_paths, pid, camid))\n",
    "    gallery_data = filtered_gallery_data\n",
    "\n",
    "    final_gallery_samples = []\n",
    "    gallery_tid = 1\n",
    "    for (img_paths, pid, camid) in gallery_data:\n",
    "        for p in img_paths:\n",
    "            final_gallery_samples.append((p, pid, camid, gallery_tid))\n",
    "        gallery_tid += 1\n",
    "\n",
    "    gallery_image_paths = [x[0] for x in final_gallery_samples]\n",
    "    gallery_pids        = [x[1] for x in final_gallery_samples]\n",
    "    gallery_camids      = [x[2] for x in final_gallery_samples]\n",
    "    gallery_tids        = [x[3] for x in final_gallery_samples]\n",
    "\n",
    "    #--------------------------------\n",
    "    # (3) モデルの準備 (ResNet50)\n",
    "    #--------------------------------\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = models.resnet50(pretrained=False)\n",
    "    model.fc = nn.Identity()\n",
    "    checkpoint = torch.load(\"C:/Users/sugie/PycharmProjects/pythonProject10/MARS/resnet50_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter.pth\", map_location=device)\n",
    "    state_dict = checkpoint.get(\"state_dict\", checkpoint)\n",
    "    state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.to(device).eval()\n",
    "\n",
    "    #--------------------------------\n",
    "    # (4) 変換定義\n",
    "    #--------------------------------\n",
    "    transform_no_aug = transforms.Compose([\n",
    "        transforms.Resize((256, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    def get_aug_transform():\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomResizedCrop(\n",
    "                size=(256, 128),\n",
    "                scale=(0.8, 1.0),\n",
    "                ratio=(0.75, 1.3333)\n",
    "            ),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1\n",
    "            ),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225]),\n",
    "            transforms.RandomErasing(p=0.5, scale=(0.02, 0.25))\n",
    "        ])\n",
    "\n",
    "    #--------------------------------\n",
    "    # (5) Dataset & Loader: Query は従来通り\n",
    "    #--------------------------------\n",
    "    query_dataset_noaug = ImageDataset(query_image_paths, transform_no_aug, is_aug=0, aug_id=0)\n",
    "    query_loader_noaug  = DataLoader(query_dataset_noaug, batch_size=64, shuffle=False, collate_fn=skip_none_collate)\n",
    "\n",
    "    #--------------------------------\n",
    "    # (★A) Train: PIDごとに50刻みで分割してpkl出力\n",
    "    #--------------------------------\n",
    "    # Train全体のサンプル（final_train_samples）は (img_path, pid, camid, tracklet_id)\n",
    "    # PIDを 0～49, 50～99, ... と分割します。\n",
    "    unique_train_pids = sorted(list(set(train_pids)))\n",
    "    chunk_size = 50\n",
    "    chunk_starts = list(range(0, 3001, chunk_size))\n",
    "    # Train用Augmentation回数（必要なら変更）\n",
    "    N_AUG_TRAIN = 0\n",
    "\n",
    "    for start_pid in chunk_starts:\n",
    "        end_pid = start_pid + chunk_size\n",
    "        train_pkl_path_chunk = f\"train_embeddings_chunk_ReSNet_all_{start_pid}_{end_pid-1}.pkl\"\n",
    "        # PIDが [start_pid, end_pid-1] のサンプルを抽出\n",
    "        chunk_indices = [i for i, pid in enumerate(train_pids) if start_pid <= pid < end_pid]\n",
    "        if len(chunk_indices) == 0:\n",
    "            continue\n",
    "        chunk_image_paths = [train_image_paths[i] for i in chunk_indices]\n",
    "        chunk_pids        = [train_pids[i]        for i in chunk_indices]\n",
    "        chunk_camids      = [train_camids[i]      for i in chunk_indices]\n",
    "        chunk_tids        = [train_tids[i]        for i in chunk_indices]\n",
    "\n",
    "        # ---- (A) オリジナル ----\n",
    "        train_dataset_noaug_chunk = ImageDataset(\n",
    "            chunk_image_paths,\n",
    "            transform_no_aug,\n",
    "            is_aug=0, aug_id=0\n",
    "        )\n",
    "        train_loader_noaug_chunk  = DataLoader(\n",
    "            train_dataset_noaug_chunk,\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            collate_fn=skip_none_collate\n",
    "        )\n",
    "\n",
    "        extract_embeddings_and_save_batchwise_pkl(\n",
    "            dataloader=train_loader_noaug_chunk,\n",
    "            model=model,\n",
    "            device=device,\n",
    "            pkl_path=train_pkl_path_chunk,\n",
    "            pids=chunk_pids,\n",
    "            camids=chunk_camids,\n",
    "            tids=chunk_tids,\n",
    "            is_aug=0,\n",
    "            aug_id=0,\n",
    "            append_mode=False\n",
    "        )\n",
    "\n",
    "        # ---- (B) オーグメンテーション（N_AUG_TRAIN回）----\n",
    "        for aug_i in range(1, N_AUG_TRAIN+1):\n",
    "            transform_aug = get_aug_transform()\n",
    "            train_dataset_aug_chunk = ImageDataset(\n",
    "                chunk_image_paths,\n",
    "                transform_aug,\n",
    "                is_aug=1, aug_id=aug_i\n",
    "            )\n",
    "            train_loader_aug_chunk  = DataLoader(\n",
    "                train_dataset_aug_chunk,\n",
    "                batch_size=64,\n",
    "                shuffle=False,\n",
    "                collate_fn=skip_none_collate\n",
    "            )\n",
    "\n",
    "            extract_embeddings_and_save_batchwise_pkl(\n",
    "                dataloader=train_loader_aug_chunk,\n",
    "                model=model,\n",
    "                device=device,\n",
    "                pkl_path=train_pkl_path_chunk,\n",
    "                pids=chunk_pids,\n",
    "                camids=chunk_camids,\n",
    "                tids=chunk_tids,\n",
    "                is_aug=1,\n",
    "                aug_id=aug_i,\n",
    "                append_mode=True\n",
    "            )\n",
    "        print(f\"Done train chunk [PID {start_pid}..{end_pid-1}]. PKL => {train_pkl_path_chunk}\")\n",
    "\n",
    "    # --------------------------------\n",
    "    # (★B) Query: PIDごとに50刻みで分割してpkl出力\n",
    "    # --------------------------------\n",
    "    unique_query_pids = sorted(list(set(query_pids)))\n",
    "    chunk_size = 50\n",
    "    chunk_starts = list(range(0, 3001, chunk_size))\n",
    "    N_AUG_QUERY = 3\n",
    "\n",
    "    for start_pid in chunk_starts:\n",
    "        end_pid = start_pid + chunk_size\n",
    "        query_pkl_path_chunk = f\"query_embeddings_chunk_ReSNet_all_{start_pid}_{end_pid - 1}.pkl\"\n",
    "\n",
    "        chunk_indices = [i for i, pid in enumerate(query_pids) if start_pid <= pid < end_pid]\n",
    "        if len(chunk_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        chunk_image_paths = [query_image_paths[i] for i in chunk_indices]\n",
    "        chunk_pids = [query_pids[i] for i in chunk_indices]\n",
    "        chunk_camids = [query_camids[i] for i in chunk_indices]\n",
    "        chunk_tids = [query_tids[i] for i in chunk_indices]\n",
    "\n",
    "        # ---- (A) オリジナル ----\n",
    "        query_dataset_noaug_chunk = ImageDataset(\n",
    "            chunk_image_paths,\n",
    "            transform_no_aug,\n",
    "            is_aug=0, aug_id=0\n",
    "        )\n",
    "        query_loader_noaug_chunk = DataLoader(\n",
    "            query_dataset_noaug_chunk,\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            collate_fn=skip_none_collate\n",
    "        )\n",
    "\n",
    "        extract_embeddings_and_save_batchwise_pkl(\n",
    "            dataloader=query_loader_noaug_chunk,\n",
    "            model=model,\n",
    "            device=device,\n",
    "            pkl_path=query_pkl_path_chunk,\n",
    "            pids=chunk_pids,\n",
    "            camids=chunk_camids,\n",
    "            tids=chunk_tids,\n",
    "            is_aug=0,\n",
    "            aug_id=0,\n",
    "            append_mode=False\n",
    "        )\n",
    "\n",
    "        # ---- (B) オーグメンテーション ----\n",
    "        for aug_i in range(1, N_AUG_QUERY + 1):\n",
    "            transform_aug = get_aug_transform()\n",
    "            query_dataset_aug_chunk = ImageDataset(\n",
    "                chunk_image_paths,\n",
    "                transform_aug,\n",
    "                is_aug=1, aug_id=aug_i\n",
    "            )\n",
    "            query_loader_aug_chunk = DataLoader(\n",
    "                query_dataset_aug_chunk,\n",
    "                batch_size=64,\n",
    "                shuffle=False,\n",
    "                collate_fn=skip_none_collate\n",
    "            )\n",
    "\n",
    "            extract_embeddings_and_save_batchwise_pkl(\n",
    "                dataloader=query_loader_aug_chunk,\n",
    "                model=model,\n",
    "                device=device,\n",
    "                pkl_path=query_pkl_path_chunk,\n",
    "                pids=chunk_pids,\n",
    "                camids=chunk_camids,\n",
    "                tids=chunk_tids,\n",
    "                is_aug=1,\n",
    "                aug_id=aug_i,\n",
    "                append_mode=True\n",
    "            )\n",
    "        print(f\"Done query chunk [PID {start_pid}..{end_pid - 1}]. PKL => {query_pkl_path_chunk}\")\n",
    "\n",
    "    #--------------------------------\n",
    "    # (★C) Gallery: PIDごとに50刻みで分割してpkl出力\n",
    "    #--------------------------------\n",
    "    unique_gallery_pids = sorted(list(set(gallery_pids)))\n",
    "    chunk_size = 25\n",
    "    chunk_starts = list(range(0, 3001, chunk_size))\n",
    "    N_AUG_GAL = 3\n",
    "\n",
    "    for start_pid in chunk_starts:\n",
    "        end_pid = start_pid + chunk_size\n",
    "        gallery_pkl_path_chunk = f\"gallery_embeddings_chunk_ReSNet_all_{start_pid}_{end_pid-1}.pkl\"\n",
    "\n",
    "        chunk_indices = [i for i, pid in enumerate(gallery_pids)\n",
    "                         if start_pid <= pid < end_pid]\n",
    "        if len(chunk_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        chunk_image_paths = [gallery_image_paths[i] for i in chunk_indices]\n",
    "        chunk_pids        = [gallery_pids[i]        for i in chunk_indices]\n",
    "        chunk_camids      = [gallery_camids[i]      for i in chunk_indices]\n",
    "        chunk_tids        = [gallery_tids[i]        for i in chunk_indices]\n",
    "\n",
    "        # ---- (A) オリジナル ----\n",
    "        gallery_dataset_noaug_chunk = ImageDataset(\n",
    "            chunk_image_paths,\n",
    "            transform_no_aug,\n",
    "            is_aug=0, aug_id=0\n",
    "        )\n",
    "        gallery_loader_noaug_chunk  = DataLoader(\n",
    "            gallery_dataset_noaug_chunk,\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            collate_fn=skip_none_collate\n",
    "        )\n",
    "\n",
    "        extract_embeddings_and_save_batchwise_pkl(\n",
    "            dataloader=gallery_loader_noaug_chunk,\n",
    "            model=model,\n",
    "            device=device,\n",
    "            pkl_path=gallery_pkl_path_chunk,\n",
    "            pids=chunk_pids,\n",
    "            camids=chunk_camids,\n",
    "            tids=chunk_tids,\n",
    "            is_aug=0,\n",
    "            aug_id=0,\n",
    "            append_mode=False\n",
    "        )\n",
    "\n",
    "        # ---- (B) オーグメンテーション ----\n",
    "        for aug_i in range(1, N_AUG_GAL+1):\n",
    "            transform_aug = get_aug_transform()\n",
    "            gallery_dataset_aug_chunk = ImageDataset(\n",
    "                chunk_image_paths,\n",
    "                transform_aug,\n",
    "                is_aug=1, aug_id=aug_i\n",
    "            )\n",
    "            gallery_loader_aug_chunk  = DataLoader(\n",
    "                gallery_dataset_aug_chunk,\n",
    "                batch_size=64,\n",
    "                shuffle=False,\n",
    "                collate_fn=skip_none_collate\n",
    "            )\n",
    "\n",
    "            extract_embeddings_and_save_batchwise_pkl(\n",
    "                dataloader=gallery_loader_aug_chunk,\n",
    "                model=model,\n",
    "                device=device,\n",
    "                pkl_path=gallery_pkl_path_chunk,\n",
    "                pids=chunk_pids,\n",
    "                camids=chunk_camids,\n",
    "                tids=chunk_tids,\n",
    "                is_aug=1,\n",
    "                aug_id=aug_i,\n",
    "                append_mode=True\n",
    "            )\n",
    "        print(f\"Done gallery chunk [PID {start_pid}..{end_pid-1}]. PKL => {gallery_pkl_path_chunk}\")\n",
    "\n",
    "    print(\"\\nAll done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daba746-c0ab-44da-b89a-0c63abb866b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
